{"cells":[{"cell_type":"markdown","metadata":{"id":"A0fH3STjC-7c"},"source":["# **DATA PREPROCESSING**"]},{"cell_type":"markdown","metadata":{"id":"i-AxzMhdDue8"},"source":["**UNZIP DATASET**"]},{"cell_type":"markdown","metadata":{"id":"2tzNh8rsD0G4"},"source":["**LIBRARIES**"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WtIn1CBpD30X"},"outputs":[],"source":["from PIL import Image\n","import numpy as np\n","from numpy import random\n","\n","\n","import os\n","import pathlib\n","import random"]},{"cell_type":"markdown","metadata":{"id":"s6L-DkiRD71Y"},"source":["**DIRECTORIES**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ep8t7VXvEAw4"},"outputs":[],"source":["# directory of dataset\n","dir_original = \"/content/drive/MyDrive/augmented_waste_dataset/content/waste_dataset/augmented_waste_dataset\"\n","\n","\n","# name of new dataset\n","dir_processed = \"/content/drive/MyDrive/augmented_waste_dataset_splited\"\n","\n"]},{"cell_type":"markdown","metadata":{"id":"xAs6OhSDEX23"},"source":["**PARAMETERS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9TKQL_-5Eb-J"},"outputs":[],"source":["# size of new images\n","size = 225, 264"]},{"cell_type":"markdown","metadata":{"id":"Ea45mcr6Efmn"},"source":["**EXTRACTION OF DATASET INFORMATION**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DBBUFW0pEkxv"},"outputs":[],"source":["data_dir = pathlib.Path(dir_original)\n","\n","set_samples = ['train', 'validation', 'test']\n","print(\"set_samples: \", set_samples, \"\\n\")\n","\n","CLASS_NAMES = np.array([item.name for item in sorted(data_dir.glob('*'))])\t\t\t\t\t\t\t\t\t\t\t\t\n","print(\"class: \", CLASS_NAMES, \"\\n\")\n","\n","N_IMAGES = np.array([len(list(data_dir.glob(item.name+'/*.jpg'))) for item in sorted(data_dir.glob('*'))])\t\t\t# number of images for class\n","print(\"number of images for class: \", N_IMAGES, \"\\n\")\n","\n","N_samples = np.array([(int(np.around(n*60/100)), int(np.around(n*15/100)), int(np.around(n*25/100))) for n in N_IMAGES])\t# number of images for set (train,validation,test)\n","print(\"split of dataset: \\n \", N_samples, \"\\n\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mRPwVXpLFlLa"},"source":["**PRE-PROCESSING DATASET**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJnREzS4FrV6"},"outputs":[],"source":["# Create the new dataset\n","# Split Dataset\t(also resize and rotate)\n","\n","\n","\n","# create the dataset folder\t\t\t***********************************\n","os.makedirs(dir_processed)\n","\n","for set_tag in set_samples:\n","\tos.makedirs(dir_processed + '/' + set_tag)\n","\n","\tfor class_name in CLASS_NAMES:\n","\t\tos.makedirs(dir_processed + '/' + set_tag + '/' + class_name)\n","\n","\n","\n","# SPLIT DATASET (and resize)\t\t*************************************\n","print(\"Split dataset.....\")\n","\n","i=0\n","j=0\n","k=0\n","for class_name in CLASS_NAMES:\t\t\t\t\t\t\t\t\t\t\t\t\n","\t\n","    print(\"class name: \", class_name)\n","\n","    contatore_samples = 0\n","    k=0\n","\n","    array = sorted(os.listdir(dir_original + '/' + class_name))\n","    #random.shuffle(array)\n","\n","    for image_name in array:\t                                       \n","\t\n","        print(\"image: \", i)\n","        i=i+1\n","\n","        if contatore_samples==N_samples[j][k]:\t\t\t\t\t\t\t\t\t\n","            k+=1\n","            contatore_samples=0\n","\n","\n","        img=Image.open(dir_original +'/'+class_name+'/'+image_name)\n","        l,_ = img.size\n","        l=int(l)\n","        \n","        \n","        if l==225 or l==264:\n","        \n","            transposed = img.transpose(Image.ROTATE_90)\n","            transposed.thumbnail(size)\n","            transposed.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n","        \n","        else:\n","        \n","            img.thumbnail(size)\n","            img.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\n","\n","        contatore_samples+=1\t\n","\n","    j+=1\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FfBSe46uGICH"},"source":["# **MODEL FOR WASTE DATASET**"]},{"cell_type":"markdown","metadata":{"id":"axfPPDSbGU5a"},"source":["**LIBRARY**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Miayf058GYuC"},"outputs":[],"source":["import tensorflow as tf\n"," \n","from tensorflow import keras\n"," \n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n"," \n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n"," \n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time"]},{"cell_type":"markdown","metadata":{"id":"lEJJMnDWGd9u"},"source":["**DIRECTORY**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W5eQGz16Gg1u"},"outputs":[],"source":["# Ditectory for the dataset\n"," \n","PATH_DATASET = '/content/drive/MyDrive/augmented_waste_dataset_splited'\n"," \n","train_data_dir = os.path.join(PATH_DATASET, 'train')\n","validation_data_dir = os.path.join(PATH_DATASET, 'validation')\n","test_data_dir = os.path.join(PATH_DATASET, 'test')\n"," \n"," \n"," \n","# Names of files to be created\n"," \n","PATH_MODELS = '/content/drive/MyDrive/Colab Notebooks/MDPI_Paper'\n"," \n","name_model_small = os.path.join(PATH_MODELS, 'model_small,h5')\n","name_model_large = os.path.join(PATH_MODELS, 'model_large.h5')"]},{"cell_type":"markdown","metadata":{"id":"kZ_2fRRpGhwv"},"source":["**PARAMETERS**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxrrtYZ2Gklu"},"outputs":[],"source":["batch_size = 32\n"," \n","nb_train_samples = 207522           # no of training samples\n","nb_validation_samples = 51880       # no of validation samples\n","nb_test_samples = 86468             # no of testing samples\n"," \n","n_class = 2\n"," \n","epochs = 50"]},{"cell_type":"markdown","metadata":{"id":"FuSRUKyvTeTm"},"source":["# **MODEL (SMALL)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6f0WEfWTiep"},"outputs":[],"source":["start = time.time()\n"," \n","# image size (Model Small)\n","img_width, img_height = 80, 45\n"," \n","# input shape\n","if keras.backend.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n"," \n"," \n"," \n","# ***********************************************************************\n","# ************        DATASET       *************************************\n","# ***********************************************************************\n"," \n","train_dataset = image_dataset_from_directory(train_data_dir,\n","                                             shuffle=True,\n","                                             batch_size=batch_size,\n","                                             image_size=(img_width, img_height),\n","                                             label_mode='categorical')\n"," \n"," \n","validation_dataset = image_dataset_from_directory(validation_data_dir,\n","                                                  shuffle=True,\n","                                                  batch_size=batch_size,\n","                                                  image_size=(img_width, img_height),\n","                                                  label_mode='categorical')\n"," \n"," \n","test_dataset = image_dataset_from_directory(test_data_dir,\n","                                            shuffle=True,\n","                                            batch_size=batch_size,\n","                                            image_size=(img_width, img_height),\n","                                            label_mode='categorical')\n"," \n"," \n","# preprocessing: input scaling (./255)\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\n"," \n","  \n","# ***********************************************************************\n","# **************        MODEL       *************************************\n","# ***********************************************************************\n"," \n","model_small = Sequential()\n","model_small.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(32, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(64, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(64, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(32, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Flatten())\n","model_small.add(Dense(64))\n","model_small.add(Activation('relu'))\n","model_small.add(Dropout(0.5))\n","model_small.add(Dense(2))           #because we have 2 class\n","model_small.add(Activation('softmax'))\n"," \n","model_small.summary()\n"," \n"," \n","# ***********************************************************************\n","# *******************        COMPILATION       **************************\n","# ***********************************************************************\n"," \n"," \n","model_small.compile(loss='categorical_crossentropy',\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\n","            metrics=['accuracy'])\n"," \n"," \n"," \n","# ***********************************************************************\n","# *******************        TRAINING       *****************************\n","# ***********************************************************************\n"," \n"," \n","with tf.device('/device:GPU:0'):\n"," \n","  history = model_small.fit(\n","    train_dataset,\n","    epochs=epochs,\n","    validation_data=validation_dataset)\n"," \n"," \n"," \n","# ***********************************************************************\n","# *****************        SAVE MODEL        ****************************\n","# ***********************************************************************\n"," \n"," \n","model_small.save(name_model_small)\n"," \n"," \n"," \n","# ***********************************************************************\n","# ********************        PLOT RESULTS        ***********************\n","# ***********************************************************************\n"," \n"," \n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n"," \n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n"," \n","epochs_range = range(epochs)\n"," \n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\n"," \n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\n","plt.show()\n"," \n"," \n"," \n","# ***********************************************************************\n","# ***********************        TEST        ****************************\n","# ***********************************************************************\n"," \n","with tf.device('/device:GPU:0'):\n"," \n","  test_result = model_small.evaluate(test_dataset)\n"," \n","  \n","print(\"size of images: \", img_width,img_height)\n","print(\"test_result: \", test_result)\n"," \n"," \n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"]},{"cell_type":"markdown","metadata":{"id":"25nIQgmGfsP2"},"source":["# **MODEL (LARGE)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LvsZJl81f5HF"},"outputs":[],"source":["start = time.time()\n","\n","# image size (Model Medium)\n","img_width, img_height = 225, 264\n","\n","# input shape\n","if keras.backend.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n","\n","\n","\n","# ***********************************************************************\n","# ************        DATASET       *************************************\n","# ***********************************************************************\n","\n","train_dataset = image_dataset_from_directory(train_data_dir,\n","                                             shuffle=True,\n","                                             batch_size=batch_size,\n","                                             image_size=(img_width, img_height),\n","                                             label_mode='categorical')\n","\n","\n","validation_dataset = image_dataset_from_directory(validation_data_dir,\n","                                                  shuffle=True,\n","                                                  batch_size=batch_size,\n","                                                  image_size=(img_width, img_height),\n","                                                  label_mode='categorical')\n","\n","\n","test_dataset = image_dataset_from_directory(test_data_dir,\n","                                            shuffle=True,\n","                                            batch_size=batch_size,\n","                                            image_size=(img_width, img_height),\n","                                            label_mode='categorical')\n","\n","\n","# preprocessing: input scaling (./255)\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\n","\n","\n","# ***********************************************************************\n","# **************        MODEL       *************************************\n","# ***********************************************************************\n","\n","model_large = Sequential()\n","model_large.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(32, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(64, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(64, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Conv2D(32, (3, 3), padding='same'))\n","model_large.add(Activation('relu'))\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model_large.add(Flatten())\n","model_large.add(Dense(64))\n","model_large.add(Activation('relu'))\n","model_large.add(Dropout(0.5))\n","model_large.add(Dense(2))\t\t\t#because we have 2 class\n","model_large.add(Activation('softmax'))\n","\n","model_large.summary()\n","\n","\n","# ***********************************************************************\n","# *******************        COMPILATION       **************************\n","# ***********************************************************************\n","\n","\n","model_large.compile(loss='categorical_crossentropy',\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\n","            metrics=['accuracy'])\n","\n","\n","\n","# ***********************************************************************\n","# *******************        TRAINING       *****************************\n","# ***********************************************************************\n","\n","\n","with tf.device('/device:GPU:0'):\n","\n","  history = model_large.fit(\n","    train_dataset,\n","    epochs=epochs,\n","    validation_data=validation_dataset)\n","\n","\n","\n","# ***********************************************************************\n","# *****************        SAVE MODEL        ****************************\n","# ***********************************************************************\n","\n","\n","model_large.save(name_model_large)\n","\n","\n","\n","# ***********************************************************************\n","# ********************        PLOT RESULTS        ***********************\n","# ***********************************************************************\n","\n","\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\n","plt.show()\n","\n","\n","\n","# ***********************************************************************\n","# ***********************        TEST        ****************************\n","# ***********************************************************************\n","\n","with tf.device('/device:GPU:0'):\n","\n","  test_result = model_large.evaluate(test_dataset)\n","\n","  \n","print(\"size of images: \", img_width,img_height)\n","print(\"test_result: \", test_result)\n","\n","\n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"waste_dataset_CNN.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
